{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcfPvkfNPN2eWTU+mAF5JU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lxyyxxx/Colab/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixd6bI-08KSt"
      },
      "source": [
        "import tensorflow as tf\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from datetime import datetime\n",
        "from typing import Any"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq7RptB-hgHc"
      },
      "source": [
        "# tensorboard\n",
        "# !rm -rf logs/mnist\n",
        "logdir = \"logs/mnist/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "GqYudQDipHD4",
        "outputId": "1a81a3f1-d82e-4314-cb04-c9361b9904a5"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs/mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 2550), started 0:53:16 ago. (Use '!kill 2550' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMWeFNlYC_BE"
      },
      "source": [
        "batch_size = 32\n",
        "lr = 0.1\n",
        "epoch = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nDKLt5t8VRw"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# batch\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V47X7vm8Yk4"
      },
      "source": [
        "class MnistModel(tf.keras.Model):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.nn = [\n",
        "            tf.keras.layers.Conv2D(16, (3, 3), input_shape=(28, 28, 1), activation='relu'),  # 无填充\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  # 最大池化\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "            tf.keras.layers.Dropout(0.25),  # 以 0.25 的概率选择神经元\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Dense(10, activation='softmax'),\n",
        "        ]\n",
        "\n",
        "    def call(self, x: Any) -> Any:\n",
        "        for layer in self.nn:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCinYAuEA_I"
      },
      "source": [
        "def learn(model: MnistModel, x: Any, y: int) -> float:\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x) # vector\n",
        "        y = tf.one_hot(y, 10) # scale to vector\n",
        "        loss = tf.reduce_mean(tf.square(y_pred - y)) # mse\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    for v, g in zip(model.trainable_weights, grads): # gd\n",
        "        v.assign_sub(g)\n",
        "    return loss, accuracy_score(tf.argmax(y_pred, axis=1).numpy(), tf.argmax(y, axis=1).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLeGjpgHnveA"
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "def figure_grid(x, y):\n",
        "    n = len(x)\n",
        "    row = 4\n",
        "    col = (n + row - 1) // row\n",
        "    figure = plt.figure(1, figsize=(24, 12))\n",
        "    plt.subplots_adjust(wspace=.5)\n",
        "    plt.gray()\n",
        "    for i in range(len(x)):\n",
        "        plt.subplot(row, col, i + 1)\n",
        "        img = x[i, :, :]\n",
        "        plt.pcolor(255 - img)  # 图像\n",
        "        plt.text(24.5, 26, '%d' % y_pred[i], color='cornflowerblue', fontsize=18)  # 标签\n",
        "        plt.xlim(0, 27)\n",
        "        plt.ylim(27, 0)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUsD8hzJmeWU"
      },
      "source": [
        "def test(model: MnistModel, x: Any, y: int):\n",
        "    x = tf.expand_dims(x, -1)\n",
        "    y_pred = tf.argmax(model(x), axis=1)\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kXV6fyA9nD5"
      },
      "source": [
        "def run_episode(epoch: int, model: MnistModel) -> None:\n",
        "    loss_all = []\n",
        "    accuracy_all = []\n",
        "    for (x_train, y_train) in train_db:\n",
        "        x_train = tf.expand_dims(x_train, -1)\n",
        "        loss, accuracy = learn(model, x_train, y_train)\n",
        "        loss_all.append(loss)\n",
        "        accuracy_all.append(accuracy)\n",
        "    loss = sum(loss_all) / len(loss_all)\n",
        "    accuracy = sum(accuracy_all) / len(accuracy_all)\n",
        "    print(\"Epoch {}, loss: {}, accuracy: {}\".format(epoch, loss, accuracy))\n",
        "    # tensorboard\n",
        "    with file_writer.as_default():\n",
        "        tf.summary.scalar('loss', data=loss, step=epoch)\n",
        "        tf.summary.scalar('accuracy', data=accuracy, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8pFtEBaGT_P",
        "outputId": "2344cca2-8175-409e-9876-64de8049e4f8"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    model = MnistModel()\n",
        "    # train\n",
        "    for e in range(epoch):\n",
        "        run_episode(e, model)\n",
        "    # test\n",
        "    y_pred_all = []\n",
        "    y_test_all = []\n",
        "    for step, (x_test, y_test) in enumerate(test_db):\n",
        "        y_pred = test(model, x_test, y_test)\n",
        "        y_pred_all.extend(y_pred.numpy())\n",
        "        y_test_all.extend(y_test)\n",
        "        figure = figure_grid(x_test, y_pred)\n",
        "        with file_writer.as_default():\n",
        "            tf.summary.image('test_results', plot_to_image(figure), step=step)\n",
        "    report = classification_report(y_pred_all, y_test_all, labels=[i for i in range(10)])\n",
        "    print(report)\n",
        "    with file_writer.as_default():\n",
        "        tf.summary.text(\"classification_report\", report, step=0)\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.012055537663400173, accuracy: 0.9154833333333333\n",
            "Epoch 1, loss: 0.003087584860622883, accuracy: 0.98005\n",
            "Epoch 2, loss: 0.002139296382665634, accuracy: 0.9864666666666667\n",
            "Epoch 3, loss: 0.0016571555752307177, accuracy: 0.9896333333333334\n",
            "Epoch 4, loss: 0.0013541723601520061, accuracy: 0.99155\n"
          ]
        }
      ]
    }
  ]
}